Practical Machine Learning Course Project
--------------------

Problem:
---------------------------
Predict how (correctly or incorrectly in 5 possible ways) a person has performed barbell lift, given data from accelerometers on the belt, forearm, arm, and dumbell. Also predict out of sample error.
Training data is downloaded from *https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv*
Test data is downoladed from *https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv*


Solution:
----------------------
As far as vast computation coud be concerned, several processes were used.
```{r}
library(doParallel)
registerDoParallel(cores=5)
```

I have downloaded data sets to my project directory in advance (in order to not tinker with file paths)

```{r}
trainingData <- read.csv("pml-training.csv",na.strings= c("NA",""," ")) 
testingData <- read.csv("pml-testing.csv",na.strings= c("NA",""," ")) 
```

Extra argument was used in order to treat empty values as NA, that made it more convenient to exclude huge piece of extra data later.

```{r}
testing <- testingData[8:length(testingData)]
training <- trainingData[8:length(trainingData)]

testing <- testing[,colSums(is.na(testing))==0]
training <- training[,colSums(is.na(training))==0]

dim(training)
dim(testing)
```
from this moment it is clear that both sets has the same structure except for the
last column (53), which is classe in training and problem_id in testing variables

The seed was set to ensure results to get reproducible.

```{r}
library(caret)
set.seed(777)
```

Due to correlation between predictors, their number was reduced
```{r}
preProc <- preProcess(training[,-53], method="pca", thresh = 0.999)
preProc
```
thus even just 48 out of 52 components seemed enough to capture key features

```{r}
trainingPC <- predict(preProc,training[,-53])
testingPC <- predict(preProc,testing[,-53])
```

To estimate out of sample error cross validation procedure was used.
```{r}
inTrain <- createDataPartition(y=training$classe, p=3/4, list=FALSE)
subTraining <- trainingPC[inTrain,]
crossVal <- trainingPC[-inTrain,]
```
As the number of components was largely reduced, random forest method was considered relevant.

```{r}
library(randomForest)
modelFit <- train(training[inTrain,53]~.,data = subTraining,method="rf")
crossValPredictions <- predict(modelFit,crossVal)
confusionMatrix(training[-inTrain,53],crossValPredictions)
```
**Accuracy > 0.99**
The achieved accuracy was considered sufficient. And hence the model was not then combined 
with any others. Therefore out of sample estimation part was complete. 
(The predicted error is actually slightly bigger, than one on the cross-validation set,
as test data had been preproccessed as a whole before that)


To submit the actual results:
- predictions were made
- piece of code from coursera page was employed

```{r}
testPredictions <- predict(modelFit,testingPC)
```
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(testPredictions)
```

